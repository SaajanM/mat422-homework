{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Elements of Linear Algebra\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/SaajanM/mat422-homework/blob/main/1.2%20Elements%20of%20Linear%20Algebra/elements_of_linear_algebra.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a numpy package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the numpy package\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand\\norm[1]{\\left\\lVert#1\\right\\rVert}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section covers the basics of linear algebra with respect to the vector space $\\mathbb{R}^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.2.0 Vector Spaces\n",
    "\n",
    "This is not directly included in the notes, however I believe it is worthwile to mention.\n",
    "\n",
    "Due to the complexity of the topic, we restrict our discussion of vector spaces to only cover spaces over the field of real numbers $\\mathbb{R}$. But it is entirely possible to replace $\\mathbb{R}$ with some other field. However, as this is a data science class, this is usually unnecessary.\n",
    "\n",
    "For a definition of a field see: [Field_(mathematics)](https://en.wikipedia.org/wiki/Field_(mathematics))\n",
    "\n",
    "**Defintion:** A set $V$ paired with operations $+$ (called vector addition) and $\\cdot$ (scalar multiplication - usually implicitly written) is called a **Vector Space** if the following properties hold: \n",
    "- For $\\mathbf{u},\\mathbf{v},\\mathbf{w}\\in V$ it holds that $\\mathbf{u}+(\\mathbf{v}+\\mathbf{w}) = (\\mathbf{u}+\\mathbf{v})+\\mathbf{w}$ (Associativity of Vector Addition)\n",
    "- For $\\mathbf{u},\\mathbf{v}\\in V$ it holds that $\\mathbf{u}+\\mathbf{v} = \\mathbf{v}+\\mathbf{u}$ (Commutativity of Vector Addition)\n",
    "- There exists an element $\\mathbf{0}\\in V$ called the **zero vector** such that $\\mathbf{v}+\\mathbf{0} = \\mathbf{v}$ for all $\\mathbf{v}\\in V$ (Additive Identity)\n",
    "- For each $\\mathbf{v}\\in V$ there exists an element $-\\mathbf{v}\\in V$ such that $\\mathbf{v} + (-\\mathbf{v}) = \\mathbf{0}$ (Additive Inverse)\n",
    "- For each $a,b\\in\\mathbb{R}$ and for each $\\mathbf{v}\\in V$ it holds that $(ab)\\mathbf{v} = a(b\\mathbf{v})$ (Scalar and Field Multiplicative Compatability)\n",
    "- There exists a scalar $1\\in \\mathbb{R}$ so that for all $\\mathbf{v}\\in V$ it holds that $1\\mathbf{v} = \\mathbf{v}$ (Multiplicative Identity)\n",
    "- For all $a,b\\in\\mathbb{R}$ and $\\mathbf{v}\\in V$ it holds that $(a+b)\\mathbf{v} = a\\mathbf{v} + b\\mathbf{v}$ (Distribution of Multiplication over Field Addition)\n",
    "- For all $\\mathbf{u},\\mathbf{v}\\in V$ and $a\\in \\mathbb{R}$ it holds that $a(\\mathbf{u} + \\mathbf{v}) = a\\mathbf{u} + a\\mathbf{v}$ (Distribution of Multiplication over Vector Addition)\n",
    "\n",
    "Vector spaces are one of the key elements of linear algebra. They form the essence of the field, with all future discussions centering around elements of such spaces. The axioms above outline enough of a \"shell\" around the sets such that we can derive several useful properties.\n",
    "\n",
    "For example, we can obtain several familiar properties, with the zero vector acting as we expect it to and the identity scalar also acting similarly as it interacts with other scalars.\n",
    "\n",
    "Note: It is interesting to point out to those familiar with matrices that the cross product is nowhere to be found. In fact the cross product is not entirely native to the concept of vector spaces and can often be better expressed through the concept of [\"an algebra over a field\"](https://en.wikipedia.org/wiki/Algebra_over_a_field). This is beyond the scope of this explainer however.\n",
    "\n",
    "In the future, we will choose $V = \\mathbb{R}^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.2.1 Linear Subspaces\n",
    "\n",
    "**Definition:** A set $U\\subseteq \\mathbb{R}^n$ is called a linear subspace if the following conditions hold:\n",
    "- For all $\\mathbf{u},\\mathbf{v}\\in U$ it is true that $\\mathbf{u} + \\mathbf{v} \\in U$ (Closure under Vector Addition)\n",
    "- For all $a\\in\\mathbb{R}$ and $\\mathbf{u}\\in U$ it is true that $a\\mathbf{u}\\in U$ (Closure under Scalar Multiplication)\n",
    "\n",
    "Often times in the vector space $\\mathbb{R}^n$, it is not useful to analyze the entire space. This is because interesting properties often crop up in smaller subspaces.\n",
    "\n",
    "Notice how $\\mathbb{R}^n\\subseteq \\mathbb{R}^n$, so $\\mathbb{R}^n$ is a linear subspace of itself. The following shows how $\\mathbb{R}^3$ is closed under vector addition and scalar multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All output vectors share the same dimensions (n=3)?: True\n"
     ]
    }
   ],
   "source": [
    "test_vectors = [np.random.rand(3) for _ in range(100)]\n",
    "\n",
    "test_scalars = [np.random.rand() for _ in range(100)]\n",
    "\n",
    "out = []\n",
    "\n",
    "for i in range(len(test_vectors)):\n",
    "    for j in range(len(test_vectors)):\n",
    "        for k in range(len(test_scalars)):\n",
    "            out.append(test_vectors[i] + test_scalars[k] * test_vectors[j])\n",
    "\n",
    "res = any([np.shape(u) == (3,) for u in out])\n",
    "print(\"All output vectors share the same dimensions (n=3)?: {}\".format(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One trivial subspace beyond the same set is the set $\\{\\mathbf{0}\\}$. We call this the zero subspace.\n",
    "\n",
    "### 1.2.1.1 Linear Combinations\n",
    "\n",
    "**Definition:** Let $W\\subseteq\\mathbb{R}^n$ be some set of vectors with $W=\\{\\mathbf{w}_1,\\dots,\\mathbf{w}_m\\}$. The **span** of $W$ is the set of all linear combinations of $W$. That is,\n",
    "$$\n",
    "\\text{span}(W) = \\left\\{\\left.\\sum_{j=1}^m a_j\\mathbf{w}_j\\right\\vert a_1,\\dots,a_j\\in\\mathbb{R}\\right\\}\n",
    "$$\n",
    "\n",
    "It is the case that every span of some set of vectors is a linear subspace of the entire vector space. The following code demonstrates this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1.2 Linear Independence and Dimension\n",
    "\n",
    "When studying some set of data, it is nice to have a description of the \"shape\" of the data to avoid having to use examples.\n",
    "\n",
    "**Defintion:** (Linear Independence) A set of vectors $\\{\\mathbf{u}_1,\\dots,\\mathbf{u}_m\\}$ is linearly\n",
    "independent if none of them can be written as a linear combination of the\n",
    "others. That is for all $1\\leq i\\leq m$\n",
    "$$\n",
    "    \\mathbf{u}_i \\not\\in \\text{span}(\\{\\mathbf{u}_j\\vert j\\neq i\\})\n",
    "$$\n",
    "\n",
    "If the above property does not hold, the set is called Linearly Dependent.\n",
    "\n",
    "An example of linear **dependence** is shown below (indepence is not possible to show via code *in general* without further theory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition:** A basis of a linear subspace $U$ is a set of vectors $B$ such that $\\text{span}(B) = U$ and $B$ is linearly independent\n",
    "\n",
    "We denote by $\\{\\mathbf{e}_1,\\dots, \\mathbf{e}_n\\}$ the standard basis of $\\mathbb{R}^n$, where $\\mathbf{e}_i$ has a one in coordinate $i$ and zeros in all other coordinates.\n",
    "\n",
    "Having a basis is nice because we can express any vector as a linear combination of the basis.\n",
    "\n",
    "This also allows us to represent linear transformations as matrices in a particular basis.\n",
    "\n",
    "**Theorem:** (Dimension Theorem) Let $U$ be a linear subspace of $\\mathbb{R}^n$. Any basis $B$ of $U$ has the same cardinality. We call this the dimension of $U$ and it gives us an idea of the \"shape\" of the subspace. We denote it $\\text{dim}(U)$\n",
    "\n",
    "The following code uses the standard basis to show that the dimension of $\\mathbb{R}^n$ is $n$ for $n=3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.2.2 Orthogonality\n",
    "\n",
    "### 1.2.2.1 Orthonormal Bases\n",
    "\n",
    "Just because all bases are of the same size for a given vector space, does not make them all equal in mathematical and analytical prowess. Often we wish to have something like the standard basis, where any \"movement\" in the direction of one of the basis vectors yields no movement in any of the others and steps are of equal size in all directions.\n",
    "\n",
    "**Definition:** The **inner product** of vectors $\\mathbf{u},\\mathbf{v}$, is  defined as $\\langle \\mathbf{u},\\mathbf{v}\\rangle = \\sum_{i}^{n}u_i v_i$.\n",
    "\n",
    "**Definition:** The **norm** of a vector $\\mathbf{u}$ is defined as $\\norm{u}=\\sqrt{\\langle\\mathbf{u},\\mathbf{u}\\rangle}$\n",
    "\n",
    "The following code snippet demostrates the built in `numpy` commands for calculating the inner product and norm of a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition:** Two vectors are **orthogonal** if the inner product of the two is zero.\n",
    "\n",
    "**Definition:** A basis is considered **orthonormal** if each of the elements are orthogonal to all the others and are all of norm one.\n",
    "\n",
    "The following code snippet shows the standard basis for $\\mathbb{R}^3$ is orthonormal. Specifically, it shows the pairwise orthogonality, since the norm of one is fairly trivial to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2.2 Best Approximation Theorem\n",
    "\n",
    "Sometimes it is difficult to use very high dimension vectors and we wish to have a close approximation in a lower dimensional space. The Best Approximation Theorem guarantees the existence of a vector in the lower dimensional space such that no other vector in the lower space is closer to the target vector in the higher space. \"Closer\" here refers to the norm of the the difference between the vectors.\n",
    "\n",
    "**Definition:** The orthogonal projection of a vector $\\mathbf{v}\\in \\mathbb{R}^n$ onto a subspace $U$ with orthonormal basis $\\{\\mathbf{u}_1,\\dots,\\mathbf{u}_m\\}$, written $\\mathscr{P}_U \\mathbf{v}$ is defined as:\n",
    "$$\n",
    "\\mathscr{P}_U \\mathbf{v} = \\sum_{j=1}^m \\langle \\mathbf{v}, \\mathbf{q}_j\\rangle \\mathbf{q}_j\n",
    "$$\n",
    "\n",
    "**Theorem:** (Best Approximation Theorem) Let $U$ be a subspace of $\\mathbb{R}^n$ and let $\\mathbf{v}\\in\\mathbb{R}^n$. For any $\\mathbf{u}\\in U$\n",
    "$$\n",
    "\\norm{\\mathbf{v}-\\mathscr{P}_U \\mathbf{v}}\\leq\\norm{\\mathbf{u}-\\mathbf{v}}\n",
    "$$\n",
    "\n",
    "In otherwords an orthonormal projection has the neat property of statisfying the Best Approximation Theorem. In fact it is the only vector that is in the \"equality\" part of the inequality.\n",
    "\n",
    "The below shows an orthogonal projection of a vector from $\\mathbb{R}^3$ to $\\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.2.3 Gram-Schmidt Process\n",
    "\n",
    "The Gram-Schmidt algorithm is used to obtain an orthonormal basis.\n",
    "\n",
    "Here is the algorithm:\n",
    "\n",
    "Take input A to be a set of linearly independent vectors $\\{\\mathbf{a}_1,\\dots,\\mathbf{a}_m\\}$\n",
    "1. Set $Q=\\varnothing$ and $i=1$\n",
    "2. Let $\\mathbf{b}_i=\\mathbf{a}_i - \\mathscr{P}_{\\text{span}(Q)} \\mathbf{a_i}$ (Note that the span of the empty set is the zero vector space)\n",
    "3. Let $\\mathbf{q}_i = \\frac{\\mathbf{b}_i}{\\norm{\\mathbf{b_i}}}$\n",
    "4. Update $Q=Q\\cup\\{\\mathbf{q}_i\\}$\n",
    "5. Update $i=i+1$\n",
    "6. Go to Step 2 if $i\\leq m$, otherwise end and output $Q$\n",
    "\n",
    "$Q$ will then be an orthonormal basis for the subspace $\\text{span}(A)$\n",
    "\n",
    "The following code demonstrates an implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.2.4 Eigenvalues and Eigenvectors\n",
    "\n",
    "### 1.2.4.1 Diagonalization of Symmetric Matrices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mat422",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
